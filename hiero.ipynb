{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f749f8ce",
   "metadata": {},
   "source": [
    "# HiERO Step Localization (Clean Version)\n",
    "\n",
    "**Function**: Use the HiERO model to perform step segmentation on EgoVLP features.\n",
    "**Features**:\n",
    "1. Fixed environment dependency conflicts (Hydra/NetworkX).\n",
    "2. Used advanced Spectral Clustering algorithm.\n",
    "3. Automatically handled PyTorch `weights_only` security error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f818ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Environment Setup\n",
    "import os\n",
    "\n",
    "# Clone HiERO repository\n",
    "if not os.path.exists('/content/HiERO'):\n",
    "    !git clone https://github.com/T-Larm/HiERO_for_egovlp.git /content/HiERO\n",
    "\n",
    "# Install core dependencies (using verified stable versions)\n",
    "print(\"ðŸ“¦ Installing dependencies...\")\n",
    "!pip install -q hydra-core omegaconf einops torch_kmeans networkx\n",
    "\n",
    "# Install PyTorch Geometric (auto-match current Colab Torch version)\n",
    "!pip install -q torch-geometric\n",
    "!pip install -q torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.5.1+cu124.html\n",
    "\n",
    "print(\"âœ… Environment installation complete! Please proceed to the next step.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50de4db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Mount Drive and Path Configuration\n",
    "import sys\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "if not os.path.exists('/content/drive'):\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# Add HiERO to system path\n",
    "if '/content/HiERO' not in sys.path:\n",
    "    sys.path.insert(0, '/content/HiERO')\n",
    "\n",
    "# ================= Path Configuration =================\n",
    "# 1. Annotation file path (If in Drive, modify here; otherwise, auto-clone project)\n",
    "PROJECT_ROOT = \"/content/aml-2025-mistake-detection-gp\"\n",
    "if not os.path.exists(PROJECT_ROOT):\n",
    "    !git clone https://github.com/T-Larm/aml-2025-mistake-detection-gp.git $PROJECT_ROOT\n",
    "\n",
    "ANNOTATIONS_PATH = os.path.join(PROJECT_ROOT, \"annotations/annotation_json/complete_step_annotations.json\")\n",
    "\n",
    "# 2. Feature and model paths (Based on your description)\n",
    "EGOVLP_FEATURES_DIR = \"/content/drive/MyDrive/AMLproject/our_features/gopro/segments/egovlp\"\n",
    "HIERO_CHECKPOINT = \"/content/drive/MyDrive/AMLproject/Captain_Cook_dataset/hiero_egovlp/hiero_egovlp.pth\"\n",
    "OUTPUT_DIR = \"/content/drive/MyDrive/AMLproject/extension1_outputs\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"ðŸ“‚ Reading features: {EGOVLP_FEATURES_DIR}\")\n",
    "print(f\"ðŸ“‚ Output results: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebab921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load HiERO Model (Fixed Version)\n",
    "import torch\n",
    "import yaml\n",
    "import hydra\n",
    "from models.hiero import HiERO\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if os.path.exists(HIERO_CHECKPOINT):\n",
    "    print(\"ðŸš€ Loading model...\")\n",
    "    \n",
    "    # Read Checkpoint (Disable weights_only security check to prevent errors)\n",
    "    try:\n",
    "        checkpoint = torch.load(HIERO_CHECKPOINT, map_location='cpu', weights_only=False)\n",
    "    except TypeError:\n",
    "        checkpoint = torch.load(HIERO_CHECKPOINT, map_location='cpu')\n",
    "    \n",
    "    # Process configuration\n",
    "    if 'config' in checkpoint:\n",
    "        config = checkpoint['config']\n",
    "    else:\n",
    "        config = {'model': {'conv': 'TDGC', 'hidden_size': 256, 'k': 2.0, 'n_layers': 2}}\n",
    "\n",
    "    model_config = config.get('model', {}).copy()\n",
    "    \n",
    "    # Clean up Hydra residual parameters\n",
    "    for key in ['_target_', '_recursive_', '_convert_']:\n",
    "        model_config.pop(key, None)\n",
    "    \n",
    "    if isinstance(model_config.get('conv'), str):\n",
    "        model_config['conv'] = {'name': model_config['conv']}\n",
    "\n",
    "    # Initialize\n",
    "    hiero_model = HiERO(input_size=256, **model_config)\n",
    "    \n",
    "    # Load weights\n",
    "    state_dict = checkpoint.get('state_dict', checkpoint.get('model', checkpoint))\n",
    "    new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "    hiero_model.load_state_dict(new_state_dict, strict=False)\n",
    "    \n",
    "    hiero_model = hiero_model.to(device).eval()\n",
    "    print(\"âœ… HiERO model loaded successfully!\")\n",
    "else:\n",
    "    print(f\"âŒ Model file not found: {HIERO_CHECKPOINT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab34cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define core segmentation function (includes Spectral Clustering and post-processing)\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "\n",
    "def detect_steps_with_hiero(features, model, device, n_clusters='auto', use_spectral=True, stride_seconds=None, fps=30):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        stride_seconds: Feature extraction stride in seconds (e.g., 1.0 for 1s). If None, uses stride=16 frames.\n",
    "        fps: Video frame rate (default: 30)\n",
    "    \"\"\"\n",
    "    T, D = features.shape\n",
    "\n",
    "    # 1. Auto-estimate number of clusters\n",
    "    if n_clusters == 'auto':\n",
    "        n_clusters = max(3, min(T // 30, 15))\n",
    "        n_clusters = int(n_clusters)\n",
    "\n",
    "    # 2. Construct graph data (with all required attributes for HiERO)\n",
    "    x = torch.from_numpy(features).float().to(device)\n",
    "    edge_index = []\n",
    "    for i in range(T - 1):\n",
    "        edge_index.append([i, i + 1])\n",
    "        edge_index.append([i + 1, i])\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous().to(device)\n",
    "    \n",
    "    # Calculate stride_frames based on metadata or default\n",
    "    if stride_seconds is not None:\n",
    "        # Use stride from file metadata (e.g., 1s_1s.npz means 1 second stride)\n",
    "        stride_frames = stride_seconds * fps\n",
    "    else:\n",
    "        # Default EgoVLP config: stride=16 frames\n",
    "        stride_frames = 16\n",
    "    \n",
    "    # Create Data object with all attributes HiERO expects (following official implementation)\n",
    "    graph_data = Data(x=x, edge_index=edge_index)\n",
    "    graph_data.batch = torch.zeros(T, dtype=torch.long, device=device)\n",
    "    graph_data.pos = ((0.5 + torch.arange(T, dtype=torch.float, device=device)) * stride_frames / fps).unsqueeze(1)  # Real timestamps in seconds\n",
    "    graph_data.indices = torch.arange(T, dtype=torch.long, device=device)  # Frame indices\n",
    "    graph_data.mask = torch.ones(T, dtype=torch.bool, device=device)  # Valid frame mask\n",
    "\n",
    "    # 3. Model inference\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            output = model(graph_data)\n",
    "            if isinstance(output, Data):\n",
    "                hiero_features = output.x\n",
    "            elif isinstance(output, dict):\n",
    "                hiero_features = output.get('x', output.get('features', x))\n",
    "            else:\n",
    "                hiero_features = output\n",
    "            \n",
    "            if len(hiero_features) > T: hiero_features = hiero_features[:T]\n",
    "            hiero_features = hiero_features.cpu().numpy()\n",
    "        except Exception as e:\n",
    "            print(f\"  âš ï¸ HiERO inference failed, using original features: {e}\")\n",
    "            hiero_features = features\n",
    "\n",
    "    # 4. Spectral Clustering\n",
    "    features_norm = hiero_features / (np.linalg.norm(hiero_features, axis=1, keepdims=True) + 1e-8)\n",
    "    affinity = features_norm @ features_norm.T\n",
    "    clustering = SpectralClustering(n_clusters=n_clusters, affinity='precomputed', random_state=42, assign_labels='kmeans')\n",
    "    labels = clustering.fit_predict(affinity)\n",
    "\n",
    "    # 5. Convert to boundaries (with post-processing)\n",
    "    boundaries = []\n",
    "    current_start = 0\n",
    "    for i in range(1, len(labels)):\n",
    "        if labels[i] != labels[current_start]:\n",
    "            if i - current_start >= 5: # Minimum length filtering\n",
    "                boundaries.append((current_start, i - 1))\n",
    "                current_start = i\n",
    "    if len(labels) - current_start >= 5:\n",
    "        boundaries.append((current_start, len(labels) - 1))\n",
    "    \n",
    "    # Extract Embedding\n",
    "    step_embeddings = []\n",
    "    for s, e in boundaries:\n",
    "        step_embeddings.append(hiero_features[s:e+1].mean(axis=0))\n",
    "    \n",
    "    return boundaries, np.stack(step_embeddings) if step_embeddings else np.zeros((0, 256))\n",
    "\n",
    "print(\"âœ… Core algorithm function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228ee5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Batch Process Videos (Main Loop)\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Prepare ID list\n",
    "with open(ANNOTATIONS_PATH, 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "available_features = {f.split('_')[0] + '_' + f.split('_')[1] for f in os.listdir(EGOVLP_FEATURES_DIR) if f.endswith('.npz')}\n",
    "common_ids = list(set(annotations.keys()).intersection(available_features))\n",
    "\n",
    "print(f\"ðŸš€ Starting processing {len(common_ids)} videos...\")\n",
    "\n",
    "hiero_results = {}\n",
    "failed = []\n",
    "\n",
    "for vid in tqdm(common_ids):\n",
    "    try:\n",
    "        # Load features\n",
    "        f_name = [f for f in os.listdir(EGOVLP_FEATURES_DIR) if f.startswith(vid)][0]\n",
    "        data = np.load(os.path.join(EGOVLP_FEATURES_DIR, f_name))\n",
    "        feats = data['arr_0'] if 'arr_0' in data else data['features']\n",
    "        \n",
    "        # Clean NaNs\n",
    "        if np.isnan(feats).any(): feats = np.nan_to_num(feats)\n",
    "        \n",
    "        # Parse stride from filename (e.g., \"xxx_1s_1s.npz\" means stride=1s)\n",
    "        stride_match = re.search(r'_(\\d+\\.?\\d*)s_', f_name)\n",
    "        stride_seconds = float(stride_match.group(1)) if stride_match else None\n",
    "        \n",
    "        # Run HiERO\n",
    "        bounds, embs = detect_steps_with_hiero(feats, hiero_model, device, stride_seconds=stride_seconds, fps=30)\n",
    "        \n",
    "        # Record results\n",
    "        anno = annotations[vid]\n",
    "        has_error = any(s.get('has_errors', False) for s in anno.get('steps', []))\n",
    "        \n",
    "        hiero_results[vid] = {\n",
    "            'boundaries': bounds,\n",
    "            'step_embeddings': embs,\n",
    "            'video_label': 1 if has_error else 0,\n",
    "            'activity': anno.get('activity_name', 'unknown')\n",
    "        }\n",
    "    except Exception as e:\n",
    "        failed.append(vid)\n",
    "\n",
    "print(f\"\\nâœ… Processing complete! Success: {len(hiero_results)}, Failed: {len(failed)}\")\n",
    "\n",
    "# Save results\n",
    "save_path = os.path.join(OUTPUT_DIR, 'hiero_step_embeddings.npz')\n",
    "np.savez(save_path, results=hiero_results)\n",
    "print(f\"ðŸ’¾ Results saved to: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
